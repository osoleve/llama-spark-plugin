{
  "mcpServers": {
    "llama": {
      "command": "python3",
      "args": ["${CLAUDE_PLUGIN_ROOT}/mcp/llama_mcp_server.py"],
      "description": "Local llama.cpp inference via llama-server"
    }
  }
}
